# 词法分析器模块详解

## Token 化的哲学

源代码对人类是连续的文本,但对编译器需要是**离散的单元序列**。

想象阅读一本外语书:如果不懂这门语言,你看到的是连续的字符流,无法理解;一旦学会分词,字符流变成单词序列,意义开始浮现。

词法分析器就是编译器的"分词器":**将连续的字符流切分成有意义的 Token 序列**。

```
字符流: "letx=42;"
   ↓ 词法分析
Token流: [LET] [IDENTIFIER,"x"] [EQUAL] [NUMBER,"42"] [SEMICOLON]
```

每个 Token 是**最小的语法单元**:

- `let`是关键字,不能拆成`l`, `e`, `t`三个字符
- `42`是数字字面量,不能拆成`4`和`2`
- `==`是一个运算符,不能拆成两个`=`

词法分析的核心挑战:**如何知道在哪里切分?**

## Token 分类的深层逻辑

### 为什么需要这么多 Token 类型?

词法分析器定义了 60+种 TokenType。为什么不简化为几种(如"单词"、"数字"、"符号")?

**因为不同 Token 在语法分析中扮演不同角色**。

考虑这些例子:

- `let`和`mut`都是关键字,但语法位置不同:`let`开始语句,`mut`修饰变量
- `+`和`*`都是运算符,但优先级不同:`*`先于`+`
- `"hello"`和`r"hello"`都是字符串,但转义规则不同

语法分析器需要这些细粒度的区分,词法分析器提前分类,简化语法分析的逻辑。

### 符号的多字符挑战

单字符符号简单:`+` → `PLUS`, `(` → `LEFT_PAREN`。

但多字符符号需要**前瞻(Lookahead)**:

```cpp
if (ch == '=') {
    if (peek() == '=') {  // 前瞻下一个字符
        return Token(EQUAL_EQUAL, "==", line, col);  // ==
    } else {
        return Token(EQUAL, "=", line, col);         // =
    }
}
```

这里的难点:**贪婪匹配**。

遇到`=`,要决定:

- 是独立的`=`(赋值)?
- 还是`==`(比较)的一部分?
- 还是`=>`(fat arrow)的一部分?

解决方案:**最长匹配原则** — 尽可能匹配更长的 Token。

```cpp
if (ch == '=') {
    if (peek() == '=') {
        consume();  // 消费第二个 =
        return Token(EQUAL_EQUAL, "==", ...);
    } else if (peek() == '>') {
        consume();  // 消费 >
        return Token(FAT_ARROW, "=>", ...);
    } else {
        return Token(EQUAL, "=", ...);
    }
}
```

这确保`==`不会错误地识别为两个`=`。

### 关键字 vs 标识符的二阶段识别

`let`, `fn`, `if`等是关键字,`x`, `foo`, `my_var`是标识符。它们的字符组成相同:字母、数字、下划线。

如何区分?

**方案 1:在扫描时判断**

- 扫描到标识符后,查询关键字表
- 是关键字返回对应 TokenType,否则返回 IDENTIFIER

**方案 2:统一识别为标识符,语法分析时区分**

- 词法分析器全部返回 IDENTIFIER
- 语法分析器检查词素,决定是否为关键字

当前实现用**方案 1**:

```cpp
string ident = scan_identifier();  // 扫描标识符
auto it = keywords.find(ident);    // 查询关键字表
if (it != keywords.end()) {
    return Token(it->second, ident, line, col);  // 关键字
} else {
    return Token(IDENTIFIER, ident, line, col);  // 普通标识符
}
```

优点:语法分析器不需要处理字符串比较,直接用 TokenType 判断。
缺点:关键字表需要维护,添加新关键字需要修改。

### 字面量的类型细分

数字字面量不仅有值,还有**类型后缀**:

- `42` → 默认 anyint
- `42i32` → 显式 i32 类型
- `42u32` → 显式 u32 类型
- `42usize` → 显式 usize 类型

为什么词法分析器要区分类型?**因为这影响后续的类型推导**。

如果词法分析器把`42i32`识别为 NUMBER,词素是`"42i32"`,类型检查器需要:

1. 从词素提取数字部分`42`
2. 从词素提取类型后缀`i32`
3. 创建对应的类型对象

这些逻辑应该在词法分析时完成,类型检查器直接使用结果。

当前设计:**调用工具函数`number_of_tokens`解析数字,获取值和类型**,然后根据类型生成对应的 Token。

## 扫描器的状态管理

### 位置追踪的双重性

词法分析器需要追踪两个位置系统:

1. **处理后文本的位置**:`current_pos`索引`content`字符串
2. **原始文件的位置**:从`positions[current_pos]`获取

为什么需要两套?

`content`是预处理后的文本,注释已删除。词法分析器在`content`中扫描,用`current_pos`追踪当前位置。但报告错误时,要用原始位置,从`positions`映射获取。

```cpp
char current_char() {
    return content[current_pos];  // 处理后文本的当前字符
}

Token create_token(TokenType type, string lexeme) {
    auto [line, col] = positions[token_start_pos];  // 原始位置
    return Token(type, lexeme, line, col);
}
```

这种设计分离了**扫描逻辑和位置报告**,让代码更清晰。

### peek 的巧妙设计

`peek()`函数返回下一个字符,但不移动位置:

```cpp
char peek() {
    if (current_pos + 1 < content.length()) {
        return content[current_pos + 1];
    }
    return '\0';  // 文件末尾
}
```

为什么返回`'\0'`而不是抛异常?

`'\0'`是**哨兵值(Sentinel Value)**:一个特殊值,表示"没有更多字符"。这让调用者不需要检查边界:

```cpp
if (current_char() == '=' && peek() == '=') {
    // 安全:peek()在EOF时返回'\0',不等于'='
}
```

如果 peek()抛异常,每次调用都要 try-catch,代码会很繁琐。哨兵值优雅地处理了边界情况。

### consume 的语义

`consume()`前进一个字符:

```cpp
void consume() {
    if (current_pos < content.length()) {
        current_pos++;
    }
}
```

为什么要封装成函数,而不是直接`current_pos++`?

**封装位置变化**:如果以后需要在前进时做额外操作(如统计字符数、记录历史),只需修改`consume()`,不需要改遍所有的`current_pos++`。

这是**信息隐藏**的原则:把可能变化的逻辑封装起来。

## 空白字符的跳过策略

词法分析器忽略空白:空格、制表符、换行符对 Token 没有意义(除了作为分隔符)。

```cpp
void skip_whitespace() {
    while (current_pos < content.length() &&
           isspace(current_char())) {
        consume();
    }
}
```

每次扫描 Token 前调用`skip_whitespace()`,确保`current_char()`指向非空白字符。

**为什么不在预处理器删除所有空白?**

因为空白在某些情况有意义:

- 字符串内的空格:`"hello world"` → 空格是字符串的一部分
- 缩进和格式:虽然不影响语义,但预处理器保留,让词法分析器位置映射更简单

预处理器删除的是**无意义的空白**(空行),保留的是**可能有意义的空白**(代码间的空格、换行)。词法分析器在扫描时决定哪些空白真正无意义,跳过它们。

## 标识符和关键字的识别

### 标识符的语法规则

Rust 的标识符规则:

- 首字符:字母或下划线
- 后续字符:字母、数字、下划线

```cpp
bool is_identifier_start(char ch) {
    return isalpha(ch) || ch == '_';
}

bool is_identifier_char(char ch) {
    return isalnum(ch) || ch == '_';
}

string scan_identifier() {
    size_t start = current_pos;
    consume();  // 跳过首字符(已验证合法)

    while (current_pos < content.length() &&
           is_identifier_char(current_char())) {
        consume();
    }

    return content.substr(start, current_pos - start);
}
```

这个循环是**贪婪的**:尽可能多地消费字符,直到遇到非标识符字符。

例如,对于`let_x_123+1`:

- `scan_identifier()`消费`let_x_123`
- 停在`+`,因为`+`不是标识符字符
- 返回`"let_x_123"`

### 关键字表的实现

关键字用哈希表存储:

```cpp
unordered_map<string, TokenType> keywords = {
    {"as", TokenType::KW_AS},
    {"break", TokenType::KW_BREAK},
    {"const", TokenType::KW_CONST},
    // ... 60+个关键字
};
```

查询时间 O(1),高效。

为什么用`unordered_map`而不是`map`?

- `map`:红黑树,有序,查询 O(log n)
- `unordered_map`:哈希表,无序,查询 O(1)

关键字不需要有序,只需快速查询,所以哈希表更合适。

### 原始标识符(Raw Identifiers)

Rust 支持`r#`前缀将关键字用作标识符:

```rust
let r#fn = 42;  // fn是关键字,但r#fn是合法的标识符
```

当前实现**未支持**这个特性。完整实现需要:

```cpp
if (current_char() == 'r' && peek() == '#') {
    consume();  // 消费 r
    consume();  // 消费 #
    string ident = scan_identifier();
    return Token(IDENTIFIER, "r#" + ident, ...);  // 强制为标识符,不查关键字表
}
```

这是语言特性的权衡:**原始标识符很少用,实现增加复杂度,教学项目可以省略**。

- `type`: 标识 Token 的语法类别,供 Parser 使用
- `lexeme`: 保留原始文本,用于生成标识符名称、数字值等
- `line`, `column`: 错误报告时定位源码位置

**示例 Token**:

```cpp
Token(NUMBER, "42i32", 3, 10)     // 第3行第10列的数字42i32
Token(IDENTIFIER, "main", 1, 4)   // 第1行第4列的标识符main
Token(IF, "if", 5, 1)             // 第5行第1列的if关键字
```

## 核心函数

### lexer_program()

主函数,将 Prog 转换为 Token 序列。

```cpp
vector<Token> lexer_program(const Prog &program, ErrorReporter &error_reporter)
```

#### 状态变量

```cpp
bool in_string = 0;     // 在普通字符串中
bool in_string2 = 0;    // 在字符字面量中
size_t in_rstring = 0;  // 在原始字符串中(值为#的数量+1)
bool trans = 0;         // 在转义序列中
size_t i = 0;           // 当前字符索引
string token = "";      // 累积当前Token的字符
Token new_token;        // 构造中的Token
vector<Token> result;   // 结果Token列表
```

#### 主循环结构

```cpp
while (i < program.content.size()) {
    char ch = program.content[i];
    char next_ch = (i + 1 < program.content.size()) ? program.content[i + 1] : '\0';

    // 根据当前状态处理字符
    if (in_rstring > 0) {
        // 处理原始字符串
    } else if (in_string) {
        // 处理普通字符串
    } else if (in_string2) {
        // 处理字符字面量
    } else {
        // 处理普通Token
    }
}
```

**设计思想**: 使用有限状态机,根据当前状态决定如何处理字符。

### 原始字符串处理

#### check_inRstring()辅助函数

```cpp
bool check_inRstring(string &token)
```

判断 token 是否是原始字符串的起始标记。

**逻辑**:

- 单个'r' → true(r"..."格式)
- "r#", "r##", ... → true(r#"..."#格式)
- "cr#", "cr##", ... → true(cr#"..."#格式)
- 其他 → false

**示例**:

```cpp
check_inRstring("r")     → true
check_inRstring("r#")    → true
check_inRstring("r###")  → true
check_inRstring("cr##")  → true
check_inRstring("rx")    → false
```

#### 原始字符串识别

```cpp
if (in_rstring > 0) {
    token += ch;
    if (ch == '"' && in_rstring == 1) {
        in_rstring = 0;  // r"..."结束
    } else if (ch == '#') {
        // 检查是否匹配起始的#数量
        for (int i = token.size() - 1; i >= 0; --i) {
            if (token[i] == '"' && token.size() - i == in_rstring) {
                in_rstring = 0;  // r#"..."#结束
                break;
            } else if (token[i] != '#') {
                break;
            }
        }
    }
    if (!in_rstring) {
        // 生成Token
        new_token.type = (token[0] == 'c') ? RCSTRING : RSTRING;
        // ...
    }
}
```

**逻辑详解**:

1. in_rstring 记录#的数量+1
2. r"..." → in_rstring = 1,遇到"结束
3. r#"..."# → in_rstring = 2,需要"后跟 1 个#
4. r##"..."## → in_rstring = 3,需要"后跟 2 个#

**示例**:

```rust
r"abc"       → RSTRING: r"abc"
r#"a"b"#     → RSTRING: r#"a"b"#  (内部的"不结束字符串)
cr##"x"##    → RCSTRING: cr##"x"##
```

### 普通字符串处理

```cpp
else if (in_string) {
    if (trans) {
        token += ch;
        trans = 0;  // 转义字符的下一个字符
    } else if (ch == '\\') {
        token += ch;
        trans = 1;  // 开始转义
    } else if (ch == '"') {
        token += ch;
        in_string = 0;  // 字符串结束
        // 生成STRING Token
    } else {
        token += ch;
    }
    i++;
}
```

**转义处理**:

- `\"` → 双引号字符,不结束字符串
- `\\` → 反斜杠字符
- `\n` → 换行符
- 其他转义序列由 Parser 或语义分析处理

### 字符字面量处理

```cpp
else if (in_string2) {
    // 类似字符串处理,但用单引号界定
    if (ch == '\'') {
        token += ch;
        in_string2 = 0;
        // 生成CHAR Token
    }
    // ...
}
```

**规则**: 单引号内的单个字符(或转义序列),如`'a'`, `'\n'`, `'\''`。

### 符号识别

#### 符号映射表

```cpp
static unordered_map<string, TokenType> symbols = {
    {">>=", GREATER_GREATER_EQUAL},
    {"<<=", LESS_LESS_EQUAL},
    {"..=", DOT_DOT_EQUAL},
    // 三字符符号

    {"!=", BANG_EQUAL},
    {"==", EQUAL_EQUAL},
    {"::", COLON_COLON},
    // 双字符符号

    {"(", LEFT_PAREN},
    {")", RIGHT_PAREN},
    {"+", PLUS},
    // 单字符符号
};
```

**查找策略**: 最长匹配优先

```cpp
string tmp3 = string(1, ch) + string(1, next_ch) + string(1, next_next_ch);
string tmp2 = string(1, ch) + string(1, next_ch);
string tmp = string(1, ch);

if (symbols.count(tmp3)) {
    // 三字符符号
} else if (symbols.count(tmp2)) {
    // 双字符符号
} else if (symbols.count(tmp)) {
    // 单字符符号
}
```

**示例**:

- 输入`>>=` → 识别为 GREATER_GREATER_EQUAL,不是`>` `>` `=`
- 输入`==` → 识别为 EQUAL_EQUAL,不是`=` `=`
- 输入`=` → 识别为 EQUAL

### 标识符和关键字识别

#### 标识符规则

```cpp
if ((ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || ch == '_') {
    token += ch;
    while (i + 1 < program.content.size()) {
        char next = program.content[i + 1];
        if ((next >= 'a' && next <= 'z') ||
            (next >= 'A' && next <= 'Z') ||
            (next >= '0' && next <= '9') ||
            next == '_') {
            token += next;
            i++;
        } else {
            break;
        }
    }
    // 检查是否是关键字
}
```

**规则**:

- 首字符: 字母或下划线
- 后续字符: 字母、数字或下划线

#### 关键字映射表

```cpp
static unordered_map<string, TokenType> keywords = {
    {"as", AS},
    {"fn", FN},
    {"let", LET},
    {"if", IF},
    {"else", ELSE},
    {"match", MATCH},
    {"true", TRUE},
    {"false", FALSE},
    // ... 60+个关键字
};
```

#### 关键字 vs 标识符判断

```cpp
if (keywords.count(token)) {
    new_token.type = keywords[token];  // 关键字
} else {
    new_token.type = IDENTIFIER;        // 标识符
}
```

**示例**:

- `fn` → FN 关键字
- `function` → IDENTIFIER 标识符
- `if` → IF 关键字
- `if_else` → IDENTIFIER 标识符

### 数字字面量识别

数字支持多种进制和类型后缀,详细处理在`number.cpp`中。

#### 进制前缀

```cpp
0x → 十六进制  (0x1A2F)
0b → 二进制    (0b1010)
0o → 八进制    (0o755)
无前缀 → 十进制 (123)
```

#### 类型后缀

```cpp
i32   → 32位有符号整数
u32   → 32位无符号整数
isize → 指针大小的有符号整数
usize → 指针大小的无符号整数
无后缀 → 类型推导(anyint)
```

#### 下划线分隔符

```cpp
1_000_000  → 等价于 1000000
0b1010_1010 → 等价于 0b10101010
```

下划线仅用于提高可读性,在解析时被忽略。

#### 数字识别逻辑

```cpp
if (ch >= '0' && ch <= '9') {
    token += ch;
    // 继续累积数字字符和下划线
    while (i + 1 < program.content.size()) {
        char next = program.content[i + 1];
        if ((next >= '0' && next <= '9') ||
            (next >= 'a' && next <= 'z') ||
            (next >= 'A' && next <= 'Z') ||
            next == '_' || next == 'x' || next == 'b' || next == 'o') {
            token += next;
            i++;
        } else {
            break;
        }
    }
    new_token.type = NUMBER;
    // lexeme保存完整的数字字符串,包括进制前缀和类型后缀
}
```

**详细解析在 number.cpp 的 number_of_tokens()函数**。

### 空白字符处理

```cpp
if (ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r') {
    i++;  // 跳过空白字符
    continue;
}
```

**作用**: 空白字符作为 Token 分隔符,本身不生成 Token。

### 字符串起始识别

```cpp
if (ch == '"') {
    if (check_inRstring(token)) {
        token += ch;
        in_rstring = token.size();  // 记录#的数量+1
        i++;
        continue;
    } else {
        token = "";
        token += ch;
        in_string = 1;  // 进入普通字符串状态
        i++;
        continue;
    }
}
```

**逻辑**:

1. 检查是否已累积了 r 或 r#...前缀
2. 是 → 进入原始字符串模式
3. 否 → 进入普通字符串模式

### Token 生成和位置记录

```cpp
new_token.lexeme = token;
new_token.line = program.positions[i].first;
new_token.column = program.positions[i].second;
result.push_back(new_token);
token = "";  // 清空token缓冲
```

**位置查询**: 通过索引 i 访问预处理器提供的 positions 数组,获取原始行列号。

### EOF Token

```cpp
// 主循环结束后
result.push_back(Token(END_OF_FILE, "", program.positions.back().first,
                       program.positions.back().second));
```

**作用**: 标记 Token 流的结束,简化 Parser 的循环判断。

## 辅助函数

### tokenTypeToString()

将 TokenType 转换为字符串,用于调试和错误报告。

```cpp
string tokenTypeToString(TokenType type) {
    switch (type) {
    case TokenType::LEFT_PAREN: return "LEFT_PAREN";
    case TokenType::NUMBER: return "NUMBER";
    case TokenType::IF: return "IF";
    // ... 120+个case
    default: return "UNKNOWN";
    }
}
```

**用途**: Token 打印、错误消息生成。

### Token::print()

```cpp
void Token::print() const {
    cout << "Token:" << tokenTypeToString(type)
         << ", \"" << lexeme << "\""
         << " at line " << line
         << ", column " << column << endl;
}
```

**输出示例**:

```
Token:NUMBER, "42i32" at line 3, column 10
Token:IDENTIFIER, "main" at line 1, column 4
Token:IF, "if" at line 5, column 1
```

### print_lexer_result()

```cpp
void print_lexer_result(const vector<Token> &tokens) {
    puts("First Step lexer:");
    for (const auto &token : tokens) {
        token.print();
    }
    puts("");
}
```

**作用**: 打印所有 Token,用于调试 Lexer 输出。

## 错误处理

### 未知字符

```cpp
error_reporter.report_error("Unknown character: " + string(1, ch),
                            program.positions[i].first,
                            program.positions[i].second);
i++;  // 跳过错误字符,继续处理
```

**策略**: 报告错误但不停止,尽可能多地发现错误。

### 未闭合的字符串

如果文件结束时 in_string 或 in_string2 仍为 true,说明字符串未闭合。

**现状**: 当前实现未显式检查,留给 Parser 报告错误。

**改进**: 可在循环结束后添加检查:

```cpp
if (in_string || in_string2 || in_rstring) {
    error_reporter.report_error("Unclosed string or character literal");
}
```

## 处理示例

### 示例 1: 简单程序

**输入**:

```rust
fn main() {
    let x = 42;
}
```

**输出 Token 序列**:

```
FN, "fn"
IDENTIFIER, "main"
LEFT_PAREN, "("
RIGHT_PAREN, ")"
LEFT_BRACE, "{"
LET, "let"
IDENTIFIER, "x"
EQUAL, "="
NUMBER, "42"
SEMICOLON, ";"
RIGHT_BRACE, "}"
END_OF_FILE, ""
```

### 示例 2: 运算符

**输入**:

```rust
x += y >> 2;
```

**输出**:

```
IDENTIFIER, "x"
PLUS_EQUAL, "+="
IDENTIFIER, "y"
GREATER_GREATER, ">>"
NUMBER, "2"
SEMICOLON, ";"
```

注意`>>`被识别为单个 Token,不是两个`>`。

### 示例 3: 字符串

**输入**:

```rust
let s1 = "Hello";
let s2 = r#"raw "string""#;
let c = 'A';
```

**输出**:

```
LET, "let"
IDENTIFIER, "s1"
EQUAL, "="
STRING, "\"Hello\""
SEMICOLON, ";"
LET, "let"
IDENTIFIER, "s2"
EQUAL, "="
RSTRING, "r#\"raw \"string\"\"#"
SEMICOLON, ";"
LET, "let"
IDENTIFIER, "c"
EQUAL, "="
CHAR, "'A'"
SEMICOLON, ";"
```

### 示例 4: 数字

**输入**:

```rust
let a = 42;
let b = 0x1A;
let c = 0b1010;
let d = 100_000;
let e = 42u32;
```

**输出**:

```
... IDENTIFIER, "a" ...
NUMBER, "42"
... IDENTIFIER, "b" ...
NUMBER, "0x1A"
... IDENTIFIER, "c" ...
NUMBER, "0b1010"
... IDENTIFIER, "d" ...
NUMBER, "100_000"
... IDENTIFIER, "e" ...
NUMBER, "42u32"
```

## 性能分析

### 时间复杂度

O(n),n 为字符数。每个字符最多被访问常数次。

### 空间复杂度

O(m),m 为 Token 数量。Token 数量通常远小于字符数。

### 优化技术

1. **哈希表查找**: 关键字和符号使用 unordered_map,O(1)查找
2. **最长匹配**: 优先匹配长符号,减少回溯
3. **状态机**: 避免复杂的条件嵌套

## 与后续阶段的接口

### 输出给 Parser

```cpp
vector<Token> tokens = lexer_program(program, error_reporter);
Parser parser(tokens, parser_error_reporter);
```

Parser 遍历 Token 序列,根据 Token 类型构建 AST。

### Token 的使用

- `type`: Parser 用于语法分析(匹配、预测)
- `lexeme`: 生成 AST 节点(变量名、数字值)
- `line`, `column`: 错误报告

## 总结

Lexer 是编译器的基础模块,将无结构的字符流转换为有语义的 Token 流。通过精心设计的状态机和查找表,高效地完成词法分析。支持 Rust 的核心词法特性:多种字符串类型、原始字符串、多进制数字、复杂运算符等。代码结构清晰,易于扩展和维护。理解 Lexer 的工作原理,是掌握编译器前端的第一步。
