# Simple Rust 编译器 - 项目总览

## 编译器的使命

编译器是什么?**是人类意图和机器指令之间的翻译官**。程序员写下高级语言代码,表达算法和逻辑;编译器将其转换为 CPU 能理解的机器码。这个转换过程远非简单的文本替换,而是一个充满智慧的过程:理解语法、验证语义、优化性能、生成代码。

这个项目实现的是编译器的**前端部分**——从源代码到语义分析的完整流程。它回答了这些核心问题:

- 源代码在语法上正确吗?(语法分析)
- 变量和类型定义在哪里?(名称解析)
- 类型是否匹配?(类型检查)
- 常量的值是多少?(常量求值)

虽然简化,但它展示了真实编译器的核心思想和架构,是学习编译原理的绝佳范本。

## 编译流程的哲学:分层抽象

为什么编译器要分成多个阶段?**因为复杂问题需要分而治之**。

想象一下如果在一个函数里完成所有事情:读取字符、识别 Token、构建 AST、检查类型、生成代码……代码会变成无法维护的怪物。分阶段的设计让每个阶段专注于一个层次的抽象:

```
原始文本 → 字符流(预处理) → Token流(词法) → AST(语法) → 类型化AST(语义) → 中间表示 → 机器码
    ↓           ↓              ↓          ↓            ↓
  混乱       结构化         有序       有意义       可执行
```

每个阶段:

1. **输入一个层次的表示**
2. **执行特定的转换**
3. **输出更高层次的表示**

这种设计让编译器成为**管道(Pipeline)**:数据在阶段间流动,每个阶段只关心自己的职责。

## 四大阶段详解

### 阶段 1: 预处理器 - 净化文本

**本质问题**: 源代码包含很多"噪音"——注释是给人看的,编译器不需要;空白行只是格式,不影响语义。如何过滤噪音,保留精华?

**核心任务**:

- 删除注释(单行`//`和多行`/* */`)
- 移除空行,压缩空白
- **关键创新**:维护位置映射表,即使注释被删除,仍能准确报告错误位置

**输出**: 干净的文本 + 位置映射

预处理器像一个文本清洁工,为后续阶段提供无噪音的输入。但它不是简单的字符串替换——需要理解字符串字面量(不能删除字符串内的`//`),处理嵌套注释,记录位置变化。

### 阶段 2: 词法分析器 - 识别单词

**本质问题**: 字符流是连续的,如何切分成有意义的单元?`let x = 42;`不是 6 个字符,而是 5 个语法单元(let, x, =, 42, ;)。

**核心任务**:

- 扫描字符,识别边界,生成 Token
- 分类 Token:关键字、标识符、数字、字符串、运算符
- 处理特殊语法:不同进制的数字(0x, 0b, 0o)、原始字符串(r#"..."#)、类型后缀(42i32)

**输出**: Token 序列,每个 Token 包含类型、文本、位置

词法分析器像一个分词器,将连续的文本流切分成离散的单词。它是语法分析的基础——解析器不处理字符,只处理 Token。

### 阶段 3: 语法分析器 - 构建结构

**本质问题**: Token 序列是平坦的,但程序是嵌套的结构。`1 + 2 * 3`不是 5 个 Token 的列表,而是一个加法表达式,右子树是乘法表达式。如何从线性 Token 构建树状结构?

**核心任务**:

- 用 Pratt 解析算法处理表达式(优先级、结合性)
- 用递归下降处理语句和声明
- 构建抽象语法树(AST),表达程序的结构

**输出**: AST,程序的树形表示

语法分析器像一个建筑师,根据蓝图(语法规则)将材料(Token)组装成建筑(AST)。它理解优先级(`*`先于`+`),理解嵌套(if 中有 if),理解边界(哪里是表达式的结束)。

### 阶段 4: 语义分析器 - 赋予意义

**本质问题**: 语法正确不代表有意义。`let x: bool = 1 + 2;`语法无误,但类型错误——不能把整数赋给布尔变量。如何验证程序的语义?

**核心任务**:

- **名称解析**: 每个变量、函数、类型在哪定义?建立符号表,连接使用和定义
- **类型解析**: 将类型注解(TypeNode)转换为类型对象(Type)
- **类型检查**: 推导每个表达式的类型,验证类型匹配,处理类型统一(anyint)
- **常量求值**: 计算编译期常量(数组大小等)

**输出**: 类型完备的 AST,每个节点都有类型信息

语义分析器像一个审查员,不仅检查语法,还检查逻辑。它确保程序"说得通"——变量在使用前定义,类型正确匹配,常量表达式可计算。

## 数据流:信息的逐层精炼

理解编译器的关键是**理解数据在各阶段的变化**:

```
输入: "let x = 42;"                                    (字符串)
  ↓
预处理: "let x = 42;\n"                                (干净文本)
  ↓
词法: [Token(LET), Token(IDENT,"x"), Token(EQ),        (Token序列)
       Token(NUMBER,"42"), Token(SEMICOLON)]
  ↓
语法: LetStmt(                                         (AST)
        name="x",
        type=None,
        init=IntegerLiteral(42)
      )
  ↓
语义: LetStmt(                                         (类型化AST)
        name="x",
        type=anyint,
        init=IntegerLiteral(42, type=anyint),
        symbol=Symbol{name="x", type=anyint, ...}
      )
```

每个阶段都在**增加信息、增加结构、增加语义**。最终的 AST 不仅知道程序的结构,还知道每个部分的含义。

## 设计原则:工程智慧的体现

### 1. 关注点分离(Separation of Concerns)

每个模块只做一件事,做好一件事:

- 预处理器不理解语法,只处理文本
- 词法分析器不理解语义,只识别 Token
- 语法分析器不检查类型,只构建结构
- 语义分析器不生成代码,只验证语义

这让每个模块可以独立开发、测试、优化。

### 2. 渐进式复杂度(Progressive Complexity)

前面的阶段简单,后面的阶段复杂:

- 预处理器最简单:字符级操作,状态机
- 词法分析器稍复杂:模式识别,分类
- 语法分析器更复杂:递归下降,优先级处理
- 语义分析器最复杂:符号表,类型系统,多遍扫描

这符合问题的本质:越高层,语义越丰富,逻辑越复杂。

### 3. 错误恢复(Error Recovery)

编译器不是遇到第一个错误就崩溃,而是:

- 报告错误,继续处理
- 收集多个错误,一次性报告
- 提供准确的位置信息(行号、列号)

这让用户体验更好:一次修复多个问题,而不是修复一个再编译发现下一个。

### 4. 可扩展性(Extensibility)

设计预留了扩展空间:

- 访问者模式让添加新的 AST 遍历很容易
- 符号表设计支持模块和作用域
- 类型系统可以扩展新类型(泛型、trait 等)

虽然当前是简化实现,但架构支持演进到完整编译器。

## 目录结构的组织逻辑

```
compiler/
├── src/                        # 源代码:按模块分层组织
│   ├── main.cpp               # 指挥官:协调所有阶段
│   ├── pre_processor/         # 第一层:文本清理
│   ├── lexer/                 # 第二层:Token识别
│   ├── parser/                # 第三层:结构构建
│   ├── ast/                   # 数据模型:AST定义
│   ├── semantic/              # 第四层:语义验证
│   ├── error/                 # 基础设施:错误报告
│   └── tool/                  # 工具库:数字解析等
├── docs/                      # 文档:理解项目的钥匙
├── testcases/                 # 测试:质量保证
├── build/                     # 构建产物:编译输出
└── CMakeLists.txt            # 构建脚本:如何编译
```

每个目录都有明确的职责:**按功能模块分离,而不是按文件类型**。这让代码高内聚低耦合——修改词法分析器不需要翻遍整个项目,只需关注`lexer/`目录。

## 核心技术选择的权衡

### Pratt 解析器 vs 递归下降

为什么表达式解析用 Pratt,语句解析用递归下降?

**递归下降**的特点:

- 直观:语法规则直接对应函数
- 简单:没有优先级表,没有复杂逻辑
- 局限:处理运算符优先级很繁琐

**Pratt 解析器**的特点:

- 优雅:通过优先级数值自动处理优先级
- 紧凑:所有运算符共享一套解析逻辑
- 灵活:添加新运算符只需注册,不改解析代码

选择:**语句用递归下降(语句没有优先级问题),表达式用 Pratt(表达式充满运算符)**。这是两者优势的结合。

### 访问者模式 vs 虚函数

AST 节点的操作可以用虚函数:

```cpp
class Expr {
    virtual void type_check() = 0;
    virtual void resolve_names() = 0;
    virtual void generate_code() = 0;
};
```

但这有问题:**每次添加新操作,要修改所有 AST 节点类**。

访问者模式反转了依赖:

```cpp
class TypeCheckVisitor : public ExprVisitor {
    void visit(BinaryExpr* node) override { /* 类型检查逻辑 */ }
    void visit(CallExpr* node) override { /* ... */ }
};
```

**添加新操作只需添加新 Visitor,不修改 AST 定义**。这符合开闭原则(对扩展开放,对修改封闭)。

### 符号表的作用域栈设计

符号表可以用多种数据结构:

- 单层哈希表:简单,但不支持作用域
- 树形结构:直观,但查找需要向上遍历
- **栈+哈希表**:查找快(O(1)),支持嵌套

当前选择:每层作用域一个哈希表,作用域用栈管理。查找时从栈顶向栈底搜索,直到找到或到达全局作用域。

这是**性能和复杂度的平衡**:大部分程序嵌套层次不深(5 层以内),线性搜索足够快。

## 类型系统的设计哲学

### 为何需要 anyint 类型?

Rust 的整数字面量灵活:

```rust
let x = 42;      // 推导为i32
let y: u32 = 42; // 42适配为u32
```

如果`42`一开始就是`i32`,第二行就会类型错误。anyint 解决了这个问题:**字面量的类型是"待定的",根据上下文推导**。

这是**类型推导的核心思想**:不是所有类型都要程序员标注,编译器可以推导。anyint 是推导的中间状态。

### Never 类型的特殊性

Never 类型(`!`)表示"永不返回":

```rust
fn panic() -> ! {
    loop {}
}
```

它的特殊规则:**Never 可以转换为任意类型**。这让以下代码合法:

```rust
let x: i32 = if cond { 42 } else { panic() };
```

`panic()`的类型是`!`,可以匹配`i32`,整个 if 表达式类型为`i32`。

这不是随意设计,而是类型理论的结果:Never 是**底类型(Bottom Type)**,所有类型的子类型。

### 单元类型的普遍性

单元类型`()`在 Rust 中无处不在:

```rust
let x = println!("Hello");  // x的类型是()
if cond { statement; }      // if表达式可以返回()
fn foo() { }                // 无返回值函数返回()
```

为什么不用`void`?因为**`()`是一等类型,可以作为值传递**:

```rust
fn returns_unit() -> () {
    ()
}
```

这统一了语言设计:所有函数都有返回值,只是返回值可以是`()`,表示"无有意义的值"。

## 错误处理策略

### 错误 vs 警告

编译器报告两类信息:

- **错误(Error)**:程序不合法,不能继续编译
- **警告(Warning)**:程序合法但可疑,可以编译

当前实现只有错误。完整实现会有警告:

- 未使用的变量
- 可能的类型转换错误
- 死代码(unreachable code)

### 错误恢复的层次

遇到错误后如何继续?

**不恢复**:遇到第一个错误就停止

- 优点:简单
- 缺点:用户体验差,修复一个错误还要再编译才能看到下一个

**局部恢复**:跳过错误部分,继续处理其他部分

- 当前实现:类型检查失败后继续检查其他节点
- 好处:一次编译发现多个错误

**全局恢复**:插入占位符(ErrorType),让编译继续到最后

- 更好的用户体验
- 但实现复杂,需要处理错误类型的传播

当前实现是**局部恢复**,在复杂度和用户体验之间取得平衡。

## 性能考量

虽然是教学项目,但仍有性能意识:

### 智能指针的选择

AST 节点用`shared_ptr`,而不是`unique_ptr`,为什么?

- AST 节点可能被多个地方引用(如符号表也引用类型节点)
- `shared_ptr`允许共享,但有引用计数开销
- `unique_ptr`无开销,但不能共享

权衡:**灵活性优先**,编译器不是性能瓶颈(相比生成的程序)。

### 符号表查找优化

符号表用`unordered_map`(哈希表),而不是`map`(红黑树),因为:

- 哈希表查找 O(1),树查找 O(log n)
- 符号表频繁查找,性能敏感

### Token 的复制 vs 引用

Parser 消费 Token 序列,可以:

- 复制:`Token current = tokens[index];` (当前实现)
- 引用:`const Token& current = tokens[index];`

当前选择复制,因为 Token 很小(字符串+几个整数),复制成本低。如果 Token 很大,引用更好。

这些细节体现:**性能优化要基于数据特点,而不是盲目应用规则**。

## 测试策略

### 测试的分层

```
testcases/
├── lexer/     # 单元测试:只测词法分析
├── parser/    # 集成测试:测到语法分析
└── semantic/  # 端到端测试:测完整流程
```

每层测试有不同目的:

- lexer 测试:验证 Token 识别正确
- parser 测试:验证 AST 结构正确
- semantic 测试:验证类型检查正确

这是**测试金字塔**:底层测试多(快速,隔离),高层测试少(慢,全面)。

### 正面测试 vs 负面测试

测试分两类:

- **正面测试**:合法代码,应该编译成功
- **负面测试**:非法代码,应该报告特定错误

`semantic/valid/`是正面测试,`semantic/invalid/`是负面测试。

两者同样重要:正面测试验证功能,负面测试验证错误检测。

## 扩展性设计

### 当前简化 vs 完整 Rust

当前实现的简化:

- ❌ 无泛型:所有类型都是具体的
- ❌ 无 trait:没有接口和多态
- ❌ 无生命周期:没有借用检查
- ❌ 无模块系统:所有代码在一个作用域
- ❌ 无宏:不支持元编程
- ✅ 基本类型:整数、布尔、字符、字符串
- ✅ 复合类型:数组、元组、结构体
- ✅ 引用和指针:&T, &mut T, *const T, *mut T
- ✅ 控制流:if, loop, while, match
- ✅ 函数和方法:基本调用

### 扩展路径

要演进到完整编译器,需要:

1. **泛型系统**:类型参数化,单态化(Monomorphization)
2. **Trait 系统**:接口定义,trait bounds,trait 对象
3. **生命周期**:借用检查器,生命周期推导
4. **模块系统**:use, mod, pub, 可见性规则
5. **宏系统**:声明宏,过程宏,属性宏
6. **异步支持**:async/await, Future trait

但核心架构(分阶段编译,AST 设计,访问者模式)已经就位,可以逐步扩展。

## 学习路径建议

理解这个项目的顺序:

1. **先宏观,后微观**:先读总览,理解整体流程,再读各模块
2. **按阶段学习**:按预处理 → 词法 → 语法 → 语义的顺序
3. **运行测试**:运行 testcases,观察输入输出
4. **修改实验**:尝试添加新运算符、新类型,验证理解
5. **阅读代码**:读 main.cpp 开始,沿着调用链深入

每个阶段的文档都有:

- 本质问题:为什么需要这个阶段
- 工作原理:如何实现
- 实现细节:代码如何组织
- 局限性:哪些没做,为什么

理解了这个项目,就理解了编译器的本质:将人类意图转化为机器可执行的形式,这个过程充满智慧和权衡。
